{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.data.utils import save_graphs,load_graphs\n",
    "import dgl\n",
    "import json\n",
    "\n",
    "graphs, graph_labels = load_graphs('/home/hdd/qingao/graphs.bin')\n",
    "graphs_by_id = dict(zip(graph_labels[\"graph_ids\"].tolist(), graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "test_data = []\n",
    "with open('/home/l1/qingao/DeepDFA/DDFA/storage/external/test_data.json', 'r') as f:\n",
    "    for line in f:\n",
    "        test_data.append(json.loads(line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved 1882 graphs to 'graphs_test200.bin'\n"
     ]
    }
   ],
   "source": [
    "from dgl.data.utils import save_graphs\n",
    "import torch\n",
    "\n",
    "test_graph_ids = [data['Unnamed: 0'] for data in test_data]\n",
    "matched_graph_ids = [graph_id for graph_id in test_graph_ids if graph_id in graphs_by_id]\n",
    "matched_graphs = [graphs_by_id[graph_id] for graph_id in matched_graph_ids]\n",
    "\n",
    "save_graphs('/home/l1/qingao/graphs_test200.bin', matched_graphs, {'graph_ids': torch.tensor(matched_graph_ids)})\n",
    "\n",
    "print(f\"Successfully saved {len(matched_graphs)} graphs to 'graphs_test200.bin'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs, graph_labels = load_graphs('/home/l1/qingao/graphs_test200.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'graph_ids': tensor([183206, 187602, 181588,  ..., 184611, 182859, 186082])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_775135/1116558920.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load('/home/l1/qingao/DeepDFA/CodeT5/home/hdd/qingao/RMGArepair/saved_model/step5_nodes200_dec_enc_dec_gnnf_wd1e-4/pytorch_model.bin')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "def adjust_state_dict_keys(state_dict):\n",
    "    new_state_dict = {}\n",
    "    for k, v in state_dict.items():\n",
    "\n",
    "        if k.startswith('encoder.encoder.'):\n",
    "            new_key = k.replace('encoder.encoder.', 'encoder.', 1)\n",
    "\n",
    "        if 'module.' in k:\n",
    "            new_key = k.replace('module.', '', 1)\n",
    "        else:\n",
    "            new_key = k\n",
    "        new_state_dict[new_key] = v\n",
    "    return new_state_dict\n",
    "state_dict = torch.load('/home/l1/qingao/DeepDFA/CodeT5/home/hdd/qingao/RMGArepair/saved_model/step5_nodes200_dec_enc_dec_gnnf_wd1e-4/pytorch_model.bin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['shared.weight', 'encoder.encoder.embed_tokens.weight', 'encoder.encoder.block.0.module.layer.0.SelfAttention.q.weight', 'encoder.encoder.block.0.module.layer.0.SelfAttention.k.weight', 'encoder.encoder.block.0.module.layer.0.SelfAttention.v.weight', 'encoder.encoder.block.0.module.layer.0.SelfAttention.o.weight', 'encoder.encoder.block.0.module.layer.0.SelfAttention.relative_attention_bias.weight', 'encoder.encoder.block.0.module.layer.0.layer_norm.weight', 'encoder.encoder.block.0.module.layer.1.DenseReluDense.wi.weight', 'encoder.encoder.block.0.module.layer.1.DenseReluDense.wo.weight', 'encoder.encoder.block.0.module.layer.1.layer_norm.weight', 'encoder.encoder.block.1.module.layer.0.SelfAttention.q.weight', 'encoder.encoder.block.1.module.layer.0.SelfAttention.k.weight', 'encoder.encoder.block.1.module.layer.0.SelfAttention.v.weight', 'encoder.encoder.block.1.module.layer.0.SelfAttention.o.weight', 'encoder.encoder.block.1.module.layer.0.layer_norm.weight', 'encoder.encoder.block.1.module.layer.1.DenseReluDense.wi.weight', 'encoder.encoder.block.1.module.layer.1.DenseReluDense.wo.weight', 'encoder.encoder.block.1.module.layer.1.layer_norm.weight', 'encoder.encoder.block.2.module.layer.0.SelfAttention.q.weight', 'encoder.encoder.block.2.module.layer.0.SelfAttention.k.weight', 'encoder.encoder.block.2.module.layer.0.SelfAttention.v.weight', 'encoder.encoder.block.2.module.layer.0.SelfAttention.o.weight', 'encoder.encoder.block.2.module.layer.0.layer_norm.weight', 'encoder.encoder.block.2.module.layer.1.DenseReluDense.wi.weight', 'encoder.encoder.block.2.module.layer.1.DenseReluDense.wo.weight', 'encoder.encoder.block.2.module.layer.1.layer_norm.weight', 'encoder.encoder.block.3.module.layer.0.SelfAttention.q.weight', 'encoder.encoder.block.3.module.layer.0.SelfAttention.k.weight', 'encoder.encoder.block.3.module.layer.0.SelfAttention.v.weight', 'encoder.encoder.block.3.module.layer.0.SelfAttention.o.weight', 'encoder.encoder.block.3.module.layer.0.layer_norm.weight', 'encoder.encoder.block.3.module.layer.1.DenseReluDense.wi.weight', 'encoder.encoder.block.3.module.layer.1.DenseReluDense.wo.weight', 'encoder.encoder.block.3.module.layer.1.layer_norm.weight', 'encoder.encoder.block.4.module.layer.0.SelfAttention.q.weight', 'encoder.encoder.block.4.module.layer.0.SelfAttention.k.weight', 'encoder.encoder.block.4.module.layer.0.SelfAttention.v.weight', 'encoder.encoder.block.4.module.layer.0.SelfAttention.o.weight', 'encoder.encoder.block.4.module.layer.0.layer_norm.weight', 'encoder.encoder.block.4.module.layer.1.DenseReluDense.wi.weight', 'encoder.encoder.block.4.module.layer.1.DenseReluDense.wo.weight', 'encoder.encoder.block.4.module.layer.1.layer_norm.weight', 'encoder.encoder.block.5.module.layer.0.SelfAttention.q.weight', 'encoder.encoder.block.5.module.layer.0.SelfAttention.k.weight', 'encoder.encoder.block.5.module.layer.0.SelfAttention.v.weight', 'encoder.encoder.block.5.module.layer.0.SelfAttention.o.weight', 'encoder.encoder.block.5.module.layer.0.layer_norm.weight', 'encoder.encoder.block.5.module.layer.1.DenseReluDense.wi.weight', 'encoder.encoder.block.5.module.layer.1.DenseReluDense.wo.weight', 'encoder.encoder.block.5.module.layer.1.layer_norm.weight', 'encoder.encoder.block.6.module.layer.0.SelfAttention.q.weight', 'encoder.encoder.block.6.module.layer.0.SelfAttention.k.weight', 'encoder.encoder.block.6.module.layer.0.SelfAttention.v.weight', 'encoder.encoder.block.6.module.layer.0.SelfAttention.o.weight', 'encoder.encoder.block.6.module.layer.0.layer_norm.weight', 'encoder.encoder.block.6.module.layer.1.DenseReluDense.wi.weight', 'encoder.encoder.block.6.module.layer.1.DenseReluDense.wo.weight', 'encoder.encoder.block.6.module.layer.1.layer_norm.weight', 'encoder.encoder.block.7.module.layer.0.SelfAttention.q.weight', 'encoder.encoder.block.7.module.layer.0.SelfAttention.k.weight', 'encoder.encoder.block.7.module.layer.0.SelfAttention.v.weight', 'encoder.encoder.block.7.module.layer.0.SelfAttention.o.weight', 'encoder.encoder.block.7.module.layer.0.layer_norm.weight', 'encoder.encoder.block.7.module.layer.1.DenseReluDense.wi.weight', 'encoder.encoder.block.7.module.layer.1.DenseReluDense.wo.weight', 'encoder.encoder.block.7.module.layer.1.layer_norm.weight', 'encoder.encoder.block.8.module.layer.0.SelfAttention.q.weight', 'encoder.encoder.block.8.module.layer.0.SelfAttention.k.weight', 'encoder.encoder.block.8.module.layer.0.SelfAttention.v.weight', 'encoder.encoder.block.8.module.layer.0.SelfAttention.o.weight', 'encoder.encoder.block.8.module.layer.0.layer_norm.weight', 'encoder.encoder.block.8.module.layer.1.DenseReluDense.wi.weight', 'encoder.encoder.block.8.module.layer.1.DenseReluDense.wo.weight', 'encoder.encoder.block.8.module.layer.1.layer_norm.weight', 'encoder.encoder.block.9.module.layer.0.SelfAttention.q.weight', 'encoder.encoder.block.9.module.layer.0.SelfAttention.k.weight', 'encoder.encoder.block.9.module.layer.0.SelfAttention.v.weight', 'encoder.encoder.block.9.module.layer.0.SelfAttention.o.weight', 'encoder.encoder.block.9.module.layer.0.layer_norm.weight', 'encoder.encoder.block.9.module.layer.1.DenseReluDense.wi.weight', 'encoder.encoder.block.9.module.layer.1.DenseReluDense.wo.weight', 'encoder.encoder.block.9.module.layer.1.layer_norm.weight', 'encoder.encoder.block.10.module.layer.0.SelfAttention.q.weight', 'encoder.encoder.block.10.module.layer.0.SelfAttention.k.weight', 'encoder.encoder.block.10.module.layer.0.SelfAttention.v.weight', 'encoder.encoder.block.10.module.layer.0.SelfAttention.o.weight', 'encoder.encoder.block.10.module.layer.0.layer_norm.weight', 'encoder.encoder.block.10.module.layer.1.DenseReluDense.wi.weight', 'encoder.encoder.block.10.module.layer.1.DenseReluDense.wo.weight', 'encoder.encoder.block.10.module.layer.1.layer_norm.weight', 'encoder.encoder.block.11.module.layer.0.SelfAttention.q.weight', 'encoder.encoder.block.11.module.layer.0.SelfAttention.k.weight', 'encoder.encoder.block.11.module.layer.0.SelfAttention.v.weight', 'encoder.encoder.block.11.module.layer.0.SelfAttention.o.weight', 'encoder.encoder.block.11.module.layer.0.layer_norm.weight', 'encoder.encoder.block.11.module.layer.1.DenseReluDense.wi.weight', 'encoder.encoder.block.11.module.layer.1.DenseReluDense.wo.weight', 'encoder.encoder.block.11.module.layer.1.layer_norm.weight', 'encoder.encoder.final_layer_norm.weight', 'decoder.embed_tokens.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.0.SelfAttention.k.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.0.SelfAttention.o.weight', 'decoder.block.6.layer.0.layer_norm.weight', 'decoder.block.6.layer.1.EncDecAttention.q.weight', 'decoder.block.6.layer.1.EncDecAttention.k.weight', 'decoder.block.6.layer.1.EncDecAttention.v.weight', 'decoder.block.6.layer.1.EncDecAttention.o.weight', 'decoder.block.6.layer.1.layer_norm.weight', 'decoder.block.6.layer.2.DenseReluDense.wi.weight', 'decoder.block.6.layer.2.DenseReluDense.wo.weight', 'decoder.block.6.layer.2.layer_norm.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.0.SelfAttention.k.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.0.SelfAttention.o.weight', 'decoder.block.7.layer.0.layer_norm.weight', 'decoder.block.7.layer.1.EncDecAttention.q.weight', 'decoder.block.7.layer.1.EncDecAttention.k.weight', 'decoder.block.7.layer.1.EncDecAttention.v.weight', 'decoder.block.7.layer.1.EncDecAttention.o.weight', 'decoder.block.7.layer.1.layer_norm.weight', 'decoder.block.7.layer.2.DenseReluDense.wi.weight', 'decoder.block.7.layer.2.DenseReluDense.wo.weight', 'decoder.block.7.layer.2.layer_norm.weight', 'decoder.block.8.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.0.SelfAttention.k.weight', 'decoder.block.8.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.0.SelfAttention.o.weight', 'decoder.block.8.layer.0.layer_norm.weight', 'decoder.block.8.layer.1.EncDecAttention.q.weight', 'decoder.block.8.layer.1.EncDecAttention.k.weight', 'decoder.block.8.layer.1.EncDecAttention.v.weight', 'decoder.block.8.layer.1.EncDecAttention.o.weight', 'decoder.block.8.layer.1.layer_norm.weight', 'decoder.block.8.layer.2.DenseReluDense.wi.weight', 'decoder.block.8.layer.2.DenseReluDense.wo.weight', 'decoder.block.8.layer.2.layer_norm.weight', 'decoder.block.9.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.0.SelfAttention.k.weight', 'decoder.block.9.layer.0.SelfAttention.v.weight', 'decoder.block.9.layer.0.SelfAttention.o.weight', 'decoder.block.9.layer.0.layer_norm.weight', 'decoder.block.9.layer.1.EncDecAttention.q.weight', 'decoder.block.9.layer.1.EncDecAttention.k.weight', 'decoder.block.9.layer.1.EncDecAttention.v.weight', 'decoder.block.9.layer.1.EncDecAttention.o.weight', 'decoder.block.9.layer.1.layer_norm.weight', 'decoder.block.9.layer.2.DenseReluDense.wi.weight', 'decoder.block.9.layer.2.DenseReluDense.wo.weight', 'decoder.block.9.layer.2.layer_norm.weight', 'decoder.block.10.layer.0.SelfAttention.q.weight', 'decoder.block.10.layer.0.SelfAttention.k.weight', 'decoder.block.10.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.0.SelfAttention.o.weight', 'decoder.block.10.layer.0.layer_norm.weight', 'decoder.block.10.layer.1.EncDecAttention.q.weight', 'decoder.block.10.layer.1.EncDecAttention.k.weight', 'decoder.block.10.layer.1.EncDecAttention.v.weight', 'decoder.block.10.layer.1.EncDecAttention.o.weight', 'decoder.block.10.layer.1.layer_norm.weight', 'decoder.block.10.layer.2.DenseReluDense.wi.weight', 'decoder.block.10.layer.2.DenseReluDense.wo.weight', 'decoder.block.10.layer.2.layer_norm.weight', 'decoder.block.11.layer.0.SelfAttention.q.weight', 'decoder.block.11.layer.0.SelfAttention.k.weight', 'decoder.block.11.layer.0.SelfAttention.v.weight', 'decoder.block.11.layer.0.SelfAttention.o.weight', 'decoder.block.11.layer.0.layer_norm.weight', 'decoder.block.11.layer.1.EncDecAttention.q.weight', 'decoder.block.11.layer.1.EncDecAttention.k.weight', 'decoder.block.11.layer.1.EncDecAttention.v.weight', 'decoder.block.11.layer.1.EncDecAttention.o.weight', 'decoder.block.11.layer.1.layer_norm.weight', 'decoder.block.11.layer.2.DenseReluDense.wi.weight', 'decoder.block.11.layer.2.DenseReluDense.wo.weight', 'decoder.block.11.layer.2.layer_norm.weight', 'decoder.final_layer_norm.weight', 'lm_head.weight', 'flow_gnn.all_embeddings.api.weight', 'flow_gnn.all_embeddings.datatype.weight', 'flow_gnn.all_embeddings.literal.weight', 'flow_gnn.all_embeddings.operator.weight', 'flow_gnn.ggnn.linears.0.weight', 'flow_gnn.ggnn.linears.0.bias', 'flow_gnn.ggnn.gru.weight_ih', 'flow_gnn.ggnn.gru.weight_hh', 'flow_gnn.ggnn.gru.bias_ih', 'flow_gnn.ggnn.gru.bias_hh', 'flow_gnn.token_aggregation.weight_ih_l0', 'flow_gnn.token_aggregation.weight_hh_l0', 'flow_gnn.token_aggregation.bias_ih_l0', 'flow_gnn.token_aggregation.bias_hh_l0'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0540, -0.0356, -0.0273,  ...,  0.0009, -0.0418, -0.0531],\n",
       "        [-0.0241, -0.0082, -0.0544,  ...,  0.0519, -0.0543,  0.0466],\n",
       "        [-0.0366, -0.0081,  0.0606,  ...,  0.0311,  0.0177, -0.0338],\n",
       "        ...,\n",
       "        [-0.0580, -0.0010, -0.0588,  ..., -0.0052, -0.0318, -0.0420],\n",
       "        [-0.0178,  0.0292,  0.0064,  ...,  0.0386, -0.0414, -0.0064],\n",
       "        [ 0.0030,  0.0438, -0.0529,  ...,  0.0266, -0.0472, -0.0519]],\n",
       "       device='cuda:1')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "state_dict['flow_gnn.ggnn.gru.weight_hh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"encoder.embed_tokens.weight\", \"encoder.block.0.layer.0.SelfAttention.q.weight\", \"encoder.block.0.layer.0.SelfAttention.k.weight\", \"encoder.block.0.layer.0.SelfAttention.v.weight\", \"encoder.block.0.layer.0.SelfAttention.o.weight\", \"encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight\", \"encoder.block.0.layer.0.layer_norm.weight\", \"encoder.block.0.layer.1.DenseReluDense.wi.weight\", \"encoder.block.0.layer.1.DenseReluDense.wo.weight\", \"encoder.block.0.layer.1.layer_norm.weight\", \"encoder.block.1.layer.0.SelfAttention.q.weight\", \"encoder.block.1.layer.0.SelfAttention.k.weight\", \"encoder.block.1.layer.0.SelfAttention.v.weight\", \"encoder.block.1.layer.0.SelfAttention.o.weight\", \"encoder.block.1.layer.0.layer_norm.weight\", \"encoder.block.1.layer.1.DenseReluDense.wi.weight\", \"encoder.block.1.layer.1.DenseReluDense.wo.weight\", \"encoder.block.1.layer.1.layer_norm.weight\", \"encoder.block.2.layer.0.SelfAttention.q.weight\", \"encoder.block.2.layer.0.SelfAttention.k.weight\", \"encoder.block.2.layer.0.SelfAttention.v.weight\", \"encoder.block.2.layer.0.SelfAttention.o.weight\", \"encoder.block.2.layer.0.layer_norm.weight\", \"encoder.block.2.layer.1.DenseReluDense.wi.weight\", \"encoder.block.2.layer.1.DenseReluDense.wo.weight\", \"encoder.block.2.layer.1.layer_norm.weight\", \"encoder.block.3.layer.0.SelfAttention.q.weight\", \"encoder.block.3.layer.0.SelfAttention.k.weight\", \"encoder.block.3.layer.0.SelfAttention.v.weight\", \"encoder.block.3.layer.0.SelfAttention.o.weight\", \"encoder.block.3.layer.0.layer_norm.weight\", \"encoder.block.3.layer.1.DenseReluDense.wi.weight\", \"encoder.block.3.layer.1.DenseReluDense.wo.weight\", \"encoder.block.3.layer.1.layer_norm.weight\", \"encoder.block.4.layer.0.SelfAttention.q.weight\", \"encoder.block.4.layer.0.SelfAttention.k.weight\", \"encoder.block.4.layer.0.SelfAttention.v.weight\", \"encoder.block.4.layer.0.SelfAttention.o.weight\", \"encoder.block.4.layer.0.layer_norm.weight\", \"encoder.block.4.layer.1.DenseReluDense.wi.weight\", \"encoder.block.4.layer.1.DenseReluDense.wo.weight\", \"encoder.block.4.layer.1.layer_norm.weight\", \"encoder.block.5.layer.0.SelfAttention.q.weight\", \"encoder.block.5.layer.0.SelfAttention.k.weight\", \"encoder.block.5.layer.0.SelfAttention.v.weight\", \"encoder.block.5.layer.0.SelfAttention.o.weight\", \"encoder.block.5.layer.0.layer_norm.weight\", \"encoder.block.5.layer.1.DenseReluDense.wi.weight\", \"encoder.block.5.layer.1.DenseReluDense.wo.weight\", \"encoder.block.5.layer.1.layer_norm.weight\", \"encoder.block.6.layer.0.SelfAttention.q.weight\", \"encoder.block.6.layer.0.SelfAttention.k.weight\", \"encoder.block.6.layer.0.SelfAttention.v.weight\", \"encoder.block.6.layer.0.SelfAttention.o.weight\", \"encoder.block.6.layer.0.layer_norm.weight\", \"encoder.block.6.layer.1.DenseReluDense.wi.weight\", \"encoder.block.6.layer.1.DenseReluDense.wo.weight\", \"encoder.block.6.layer.1.layer_norm.weight\", \"encoder.block.7.layer.0.SelfAttention.q.weight\", \"encoder.block.7.layer.0.SelfAttention.k.weight\", \"encoder.block.7.layer.0.SelfAttention.v.weight\", \"encoder.block.7.layer.0.SelfAttention.o.weight\", \"encoder.block.7.layer.0.layer_norm.weight\", \"encoder.block.7.layer.1.DenseReluDense.wi.weight\", \"encoder.block.7.layer.1.DenseReluDense.wo.weight\", \"encoder.block.7.layer.1.layer_norm.weight\", \"encoder.block.8.layer.0.SelfAttention.q.weight\", \"encoder.block.8.layer.0.SelfAttention.k.weight\", \"encoder.block.8.layer.0.SelfAttention.v.weight\", \"encoder.block.8.layer.0.SelfAttention.o.weight\", \"encoder.block.8.layer.0.layer_norm.weight\", \"encoder.block.8.layer.1.DenseReluDense.wi.weight\", \"encoder.block.8.layer.1.DenseReluDense.wo.weight\", \"encoder.block.8.layer.1.layer_norm.weight\", \"encoder.block.9.layer.0.SelfAttention.q.weight\", \"encoder.block.9.layer.0.SelfAttention.k.weight\", \"encoder.block.9.layer.0.SelfAttention.v.weight\", \"encoder.block.9.layer.0.SelfAttention.o.weight\", \"encoder.block.9.layer.0.layer_norm.weight\", \"encoder.block.9.layer.1.DenseReluDense.wi.weight\", \"encoder.block.9.layer.1.DenseReluDense.wo.weight\", \"encoder.block.9.layer.1.layer_norm.weight\", \"encoder.block.10.layer.0.SelfAttention.q.weight\", \"encoder.block.10.layer.0.SelfAttention.k.weight\", \"encoder.block.10.layer.0.SelfAttention.v.weight\", \"encoder.block.10.layer.0.SelfAttention.o.weight\", \"encoder.block.10.layer.0.layer_norm.weight\", \"encoder.block.10.layer.1.DenseReluDense.wi.weight\", \"encoder.block.10.layer.1.DenseReluDense.wo.weight\", \"encoder.block.10.layer.1.layer_norm.weight\", \"encoder.block.11.layer.0.SelfAttention.q.weight\", \"encoder.block.11.layer.0.SelfAttention.k.weight\", \"encoder.block.11.layer.0.SelfAttention.v.weight\", \"encoder.block.11.layer.0.SelfAttention.o.weight\", \"encoder.block.11.layer.0.layer_norm.weight\", \"encoder.block.11.layer.1.DenseReluDense.wi.weight\", \"encoder.block.11.layer.1.DenseReluDense.wo.weight\", \"encoder.block.11.layer.1.layer_norm.weight\", \"encoder.final_layer_norm.weight\". "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepdfa2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
