{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.data.utils import load_graphs\n",
    "import dgl\n",
    "import pandas as pd\n",
    "\n",
    "graphs, graph_labels = load_graphs('/home/hdd/qingao/graphs.bin')\n",
    "graphs_by_id = dict(zip(graph_labels[\"graph_ids\"].tolist(), graphs))\n",
    "\n",
    "graph_ids = graph_labels[\"graph_ids\"].tolist()\n",
    "df = pd.DataFrame(graph_ids, columns=[\"graph_id\"])\n",
    "\n",
    "# 保存为 valid_index.csv\n",
    "df.to_csv(\"valid_index.csv\", index=False)\n",
    "\n",
    "\n",
    "len(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes_list = [g.number_of_nodes() for g in graphs]\n",
    "\n",
    "\n",
    "average_num_nodes = sum(num_nodes_list) / len(num_nodes_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch as th\n",
    "from tqdm import tqdm\n",
    "\n",
    "allfeats = [\n",
    "    \"api\", \"datatype\", \"literal\", \"operator\",\n",
    "]\n",
    "\n",
    "def load_additional_features(graphs_by_id, feat_names, split=\"fixed\", sample_text=\"\"):\n",
    "\n",
    "    for feat in feat_names:\n",
    "\n",
    "        prefix = \"_ABS_DATAFLOW_\"\n",
    "        filepath = f\"/home/l1/qingao/DeepDFA/DDFA/storage/processed/bigvul/nodes_feat_{prefix}{feat}_all_limitall_10000_limitsubkeys_10000_{split}{sample_text}.csv\"\n",
    "\n",
    "        feat_df = pd.read_csv(filepath, index_col=0)\n",
    "        \n",
    "\n",
    "        for graph_id, group in tqdm(feat_df.groupby(\"graph_id\"), f\"Adding feature {feat}\"):\n",
    "            if graph_id in graphs_by_id:\n",
    "                g = graphs_by_id[graph_id]\n",
    "\n",
    "                feat_column = next(c for c in feat_df.columns if c.startswith(f\"_ABS_DATAFLOW_{feat}\"))\n",
    "\n",
    "                g.ndata[f\"_ABS_DATAFLOW_{feat}\"] = th.LongTensor(group[feat_column].tolist())\n",
    "                \n",
    "    return graphs_by_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding feature api: 100%|██████████| 187062/187062 [00:05<00:00, 36671.26it/s]\n",
      "Adding feature datatype: 100%|██████████| 187062/187062 [00:04<00:00, 40901.85it/s]\n",
      "Adding feature literal: 100%|██████████| 187062/187062 [00:04<00:00, 41514.62it/s]\n",
      "Adding feature operator: 100%|██████████| 187062/187062 [00:04<00:00, 38189.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['feat', '_ABS_DATAFLOW_api', '_ABS_DATAFLOW_datatype', '_ABS_DATAFLOW_literal', '_ABS_DATAFLOW_operator'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "graphs_by_id = load_additional_features(graphs_by_id, allfeats)\n",
    "\n",
    "\n",
    "graph_id = list(graphs_by_id.keys())[0]  \n",
    "g = graphs_by_id[graph_id]\n",
    "print(g.ndata.keys())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9333\n"
     ]
    }
   ],
   "source": [
    "print(len(graphs_by_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6548/6548 [00:24<00:00, 264.59 examples/s]\n",
      "Map: 100%|██████████| 903/903 [00:03<00:00, 295.74 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import default_data_collator, get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "train_data = []\n",
    "with open('/home/l1/qingao/DeepDFA/DDFA/storage/external/train_data.json', 'r') as f:\n",
    "    for line in f:\n",
    "        train_data.append(json.loads(line))\n",
    "\n",
    "valid_index = graph_labels[\"graph_ids\"]\n",
    "\n",
    "val_data = []\n",
    "with open('/home/l1/qingao/DeepDFA/DDFA/storage/external/val_data.json', 'r') as f:\n",
    "    for line in f:\n",
    "        val_data.append(json.loads(line))\n",
    "\n",
    "valid_index = graph_labels[\"graph_ids\"]\n",
    "\n",
    "\n",
    "\n",
    "filtered_data = [item for item in train_data if item.get('Unnamed: 0') in valid_index]\n",
    "filtered_val_data = [item for item in val_data if item.get('Unnamed: 0') in valid_index]\n",
    "\n",
    "\n",
    "train_df = pd.DataFrame(filtered_data)  # 将 filtered_data 转换为 DataFrame\n",
    "val_df = pd.DataFrame(filtered_val_data)  # 将 filtered_val_data 转换为 DataFrame\n",
    "\n",
    "\n",
    "train_Ds = Dataset.from_pandas(train_df)\n",
    "val_Ds = Dataset.from_pandas(val_df)\n",
    "\n",
    "def process_func(example):\n",
    "    MAX_LENGTH = 512\n",
    "    source = ''.join(example['source']) if isinstance(example['source'], list) else example['source']\n",
    "    target = ''.join(example['target']) if isinstance(example['target'], list) else example['target']\n",
    "    inputs = tokenizer(source, truncation=True, max_length=MAX_LENGTH, padding='max_length')\n",
    "    labels = tokenizer(target, truncation=True, max_length=MAX_LENGTH, padding='max_length')\n",
    "    index = example['Unnamed: 0']\n",
    "    return {\n",
    "        \"input_ids\": inputs['input_ids'],\n",
    "        \"attention_mask\": inputs['attention_mask'],\n",
    "        \"labels\": labels['input_ids'],\n",
    "        \"index\" : torch.tensor(index)\n",
    "    }\n",
    "\n",
    "train_ds = train_Ds.map(process_func, batched=False, remove_columns=train_Ds.column_names)\n",
    "val_ds = val_Ds.map(process_func, batched=False, remove_columns=val_Ds.column_names)\n",
    "# 输出筛选后的数据\n",
    "train_dataloader = DataLoader(train_ds, collate_fn=default_data_collator, batch_size=16, pin_memory=True)\n",
    "eval_dataloader = DataLoader(val_ds, collate_fn=default_data_collator, batch_size=1, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6548"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/6548 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6548/6548 [00:23<00:00, 283.31 examples/s]\n",
      "Map: 100%|██████████| 903/903 [00:03<00:00, 294.16 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_Ds.map(process_func, batched=False, remove_columns=train_Ds.column_names)\n",
    "val_ds = val_Ds.map(process_func, batched=False, remove_columns=val_Ds.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import default_data_collator, get_linear_schedule_with_warmup\n",
    "train_dataloader = DataLoader(train_ds, collate_fn=default_data_collator, batch_size=16, pin_memory=True)\n",
    "eval_dataloader = DataLoader(val_ds, collate_fn=default_data_collator, batch_size=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_tokens(tokens):\n",
    "    tokens = tokens.replace(\"<pad>\", \"\")\n",
    "    tokens = tokens.replace(\"<s>\", \"\")\n",
    "    tokens = tokens.replace(\"</s>\", \"\")\n",
    "    tokens = tokens.replace(' ','')\n",
    "    tokens = tokens.replace(\"</s>\", \"\")\n",
    "    tokens = tokens.replace(\"<start>\", \"\").replace('<end>','')\n",
    "    tokens = re.sub(r'\\s+', ' ', tokens)\n",
    "    tokens = tokens.strip()\n",
    "    return tokens\n",
    "def eval(model,eval_dataloader,graphs_by_id):\n",
    "\n",
    "    bar = tqdm(eval_dataloader, total=len(eval_dataloader), desc=\"eval\")\n",
    "    model.to('cuda:1')\n",
    "    model.eval()\n",
    "    exmatch = 0\n",
    "    for step, batch in enumerate(bar):\n",
    "        input_ids = batch['input_ids'].to('cuda:1')\n",
    "        attention_mask = batch['attention_mask'].to('cuda:1')\n",
    "        labels = batch['labels'].to('cuda:1')\n",
    "        index = batch['index'].to('cuda:1')\n",
    "\n",
    "        index_list = index.tolist()\n",
    "\n",
    "        if graphs_by_id is None:\n",
    "            graphs = None\n",
    "        else:\n",
    "            graphs = [graphs_by_id[i].to('cuda:1') for i in index_list if i in graphs_by_id]\n",
    "\n",
    "        outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask,\n",
    "                                max_length = 128,\n",
    "                                graph=graphs if graphs else None)\n",
    "        for output,label in zip(outputs,labels):\n",
    "            if(clean_tokens(tokenizer.decode(output,skip_special_tokens=True))==clean_tokens(tokenizer.decode(label,skip_special_tokens=True))):\n",
    "                exmatch+=1\n",
    "                # print('FlowT5:',tokenizer.decode(output,skip_special_tokens=True))\n",
    "                # print('T5',tokenizer.decode(output_code,skip_special_tokens=True))\n",
    "                # print('answer',tokenizer.decode(label,skip_special_tokens=True))\n",
    "    return exmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/l1/qingao/DeepDFA\")\n",
    "import itertools\n",
    "from dgl.nn.pytorch import GatedGraphConv, GlobalAttentionPooling\n",
    "import torch\n",
    "from torch import nn\n",
    "from DDFA.code_gnn.models.base_module import BaseModule\n",
    "from pytorch_lightning.utilities.cli import MODEL_REGISTRY\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "allfeats = [\n",
    "    \"api\", \"datatype\", \"literal\", \"operator\"\n",
    "]\n",
    "\n",
    "@MODEL_REGISTRY\n",
    "class FlowGNNGGNNModule(BaseModule):\n",
    "    def __init__(self,\n",
    "                 feat,\n",
    "                 input_dim,\n",
    "                 hidden_dim,\n",
    "                 n_steps,\n",
    "                 num_output_layers,\n",
    "                 label_style=\"graph\",\n",
    "                 concat_all_absdf=False,\n",
    "                 encoder_mode=False,\n",
    "                 code_embedding_dim=768,  # CodeT5 embedding dimension\n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # if \"_ABS_DATAFLOW\" in feat:\n",
    "        #     feat = \"_ABS_DATAFLOW\"\n",
    "        # self.feature_keys = {\n",
    "        #     \"feature\": feat,\n",
    "        # }\n",
    "\n",
    "        # self.input_dim = input_dim\n",
    "        # self.concat_all_absdf = concat_all_absdf\n",
    "\n",
    "        # # Feature extractors\n",
    "        # embedding_dim = hidden_dim\n",
    "        # if self.concat_all_absdf:\n",
    "        #     self.all_embeddings = nn.ModuleDict({\n",
    "        #         of: nn.Embedding(input_dim, embedding_dim) for of in allfeats\n",
    "        #     })\n",
    "        #     embedding_dim *= len(allfeats)\n",
    "        #     hidden_dim *= len(allfeats)\n",
    "        # else:\n",
    "        #     self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "\n",
    "        # # Graph stage\n",
    "        # self.ggnn = GatedGraphConv(in_feats=embedding_dim,\n",
    "        #                            out_feats=hidden_dim,\n",
    "        #                            n_steps=n_steps,\n",
    "        #                            n_etypes=1)\n",
    "\n",
    "        # CodeT5 integration\n",
    "        # self.code_embedding_dim = code_embedding_dim\n",
    "\n",
    "        # Token-level aggregation (e.g., mean-pooling)\n",
    "        self.token_aggregation = nn.GRU(768, 768, batch_first=True)\n",
    "\n",
    "        # Output dimension calculation\n",
    "# \n",
    "\n",
    "\n",
    "    def forward(self, graph, extrafeats):\n",
    "        \"\"\"\n",
    "        graph: DGL graph object\n",
    "        extrafeats: extra features (node-related features)\n",
    "        code_embeddings: precomputed embeddings from CodeT5 for the 'code' in nodes\n",
    "        \"\"\"\n",
    "\n",
    "        code_embeddings = graph.ndata['feat']  \n",
    "\n",
    "        # if self.concat_all_absdf:\n",
    "        #     cfeats = []\n",
    "        #     for otherfeat in allfeats:\n",
    "        #         feat = graph.ndata[f\"_ABS_DATAFLOW_{otherfeat}\"]\n",
    "        #         cfeats.append(self.all_embeddings[otherfeat](feat))\n",
    "        #     feat_embed = torch.cat(cfeats, dim=1)  \n",
    "        # else:\n",
    "        #     feat = graph.ndata[self.feature_keys[\"feature\"]]\n",
    "        #     feat_embed = self.embedding(feat)\n",
    "\n",
    "        # # Graph learning stage (GGNN)\n",
    "        # ggnn_out = self.ggnn(graph, feat_embed)\n",
    "        # print(\"GGNN Output Size:\", ggnn_out.size())\n",
    "\n",
    "        # Token-level aggregation (reduce sequence dimension)\n",
    "\n",
    "        code_embeddings = code_embeddings.view(-1, code_embeddings.size(1), 768)  # [node_num, seq_len, hid_dim]\n",
    "\n",
    "        # 进行 GRU 聚合\n",
    "        output, code_embeddings_agg = self.token_aggregation(code_embeddings)\n",
    "\n",
    "        # Expand aggregated CodeT5 embeddings to match GGNN output size\n",
    "        code_embeddings = code_embeddings_agg.squeeze(0)\n",
    "        # print('code_embeddings',code_embeddings.size())\n",
    "\n",
    "        # Concatenate GGNN output, node features, and CodeT5 embeddings\n",
    "        # out = torch.cat([ggnn_out, feat_embed, code_embeddings], dim=-1)\n",
    "\n",
    "        # If you're generating node-level outputs, just return out\n",
    "        logits = code_embeddings  # Remove pooling if not needed\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1015576/2036943761.py:351: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('/home/hdd/qingao/DeepDFA/CodeT5/saved_models/repair/codeT5/checkpoint-best-acc/pytorch_model.bin'))\n"
     ]
    }
   ],
   "source": [
    "import types\n",
    "import torch\n",
    "import transformers\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('/home/l1/qingao/DeepDFA/CodeT5')\n",
    "from modeling_t5 import T5ForConditionalGeneration\n",
    "\n",
    "class FLOWT5(T5ForConditionalGeneration):\n",
    "    def __init__(self, config,flow_gnn):\n",
    "        super().__init__(config)\n",
    "        self.flow_gnn = flow_gnn\n",
    "        self.wrap_encoder()\n",
    "\n",
    "    def forward_(self, **kwargs):\n",
    "        if 'input_ids' in kwargs:\n",
    "            kwargs['input_ids'] = kwargs['input_ids'].view(kwargs['input_ids'].size(0), -1)\n",
    "        if 'attention_mask' in kwargs:\n",
    "            kwargs['attention_mask'] = kwargs['attention_mask'].view(kwargs['attention_mask'].size(0), -1)\n",
    "\n",
    "        return super(FLOWT5, self).forward(\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    # We need to resize as B x (N * L) instead of (B * N) x L here\n",
    "    # because the T5 forward method uses the input tensors to infer\n",
    "    # dimensions used in the decoder.\n",
    "    # EncoderWrapper resizes the inputs as (B * N) x L.\n",
    "    def forward(self, input_ids=None, attention_mask=None, graph=None, **kwargs):\n",
    "    # 获取 ggnn_output\n",
    "        ggnn_output = None\n",
    "        padding_length = 200\n",
    "        if graph is not None:\n",
    "            ggnn_output = torch.zeros(input_ids.size(0), padding_length, 768) # b,200,768\n",
    "            num_nodes = []\n",
    "            i = 0\n",
    "            for g in graph:\n",
    "                \n",
    "                out = self.flow_gnn(g, {})  # ggnn_output 的形状为 1，N, 718\n",
    "                if out.size(0)<padding_length:\n",
    "                    ggnn_output[i, :out.size(0)] = out \n",
    "                else:\n",
    "                    ggnn_output[i, :, :] = out[:padding_length,:] \n",
    "                i += 1\n",
    "                num_nodes.append(out.size(0))\n",
    "        self.encoder.gnn_out = ggnn_output\n",
    "\n",
    "        # print(ggnn_output.size())\n",
    "\n",
    "        if input_ids is not None:\n",
    "\n",
    "            if input_ids.dim() == 3:\n",
    "                self.encoder.n_passages = input_ids.size(1)\n",
    "            input_ids = input_ids.view(input_ids.size(0), -1).long()  \n",
    "            if ggnn_output is not None:\n",
    "                padding = torch.zeros(input_ids.size(0), padding_length, dtype=input_ids.dtype, device=input_ids.device)  # (batch_size, num_nodes)\n",
    "\n",
    "\n",
    "                input_ids = torch.cat((input_ids, padding), dim=1)\n",
    "\n",
    "        if attention_mask is not None:\n",
    "            attention_mask = attention_mask.view(attention_mask.size(0), -1)  \n",
    "            if ggnn_output is not None:\n",
    "\n",
    "                padding = torch.ones(input_ids.size(0), padding_length, dtype=input_ids.dtype, device=input_ids.device)  # (batch_size, num_nodes)\n",
    "                for i, num in enumerate(num_nodes):\n",
    "\n",
    "                    padding[i, :num] = 1\n",
    "\n",
    "                attention_mask = torch.cat((attention_mask, padding), dim=1)\n",
    "\n",
    "\n",
    "        # print('input_ids',input_ids.size())\n",
    "        # print('attention_mask',attention_mask.size())\n",
    "        return super().forward(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask, \n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    # We need to resize the inputs here, as the generate method expect 2D tensors\n",
    "    def generate(self, input_ids, attention_mask, max_length, graph,**kwargs):\n",
    "        self.encoder.n_passages = input_ids.size(1)\n",
    "        ggnn_output = None\n",
    "        padding_length = 200\n",
    "        if graph is not None:\n",
    "            ggnn_output = torch.zeros(input_ids.size(0), padding_length, 768)\n",
    "            num_nodes = []\n",
    "            i = 0\n",
    "            for g in graph:\n",
    "                \n",
    "                out = self.flow_gnn(g, {})  \n",
    "                if out.size(0)<padding_length:\n",
    "                    ggnn_output[i, :out.size(0)] = out \n",
    "                else:\n",
    "                    ggnn_output[i, :, :] = out[:padding_length,:] \n",
    "                num_nodes.append(out.size(0))\n",
    "                i = i + 1\n",
    "        self.encoder.gnn_out = ggnn_output\n",
    "\n",
    "        if input_ids is not None:\n",
    "\n",
    "            if input_ids.dim() == 3:\n",
    "                self.encoder.n_passages = input_ids.size(1)\n",
    "            input_ids = input_ids.view(input_ids.size(0), -1).long()  \n",
    "            if ggnn_output is not None:\n",
    "                padding = torch.zeros(input_ids.size(0), padding_length, dtype=input_ids.dtype, device=input_ids.device)  # (batch_size, num_nodes)\n",
    "\n",
    "\n",
    "    \n",
    "                input_ids = torch.cat((input_ids, padding), dim=1)\n",
    "        if attention_mask is not None:\n",
    "            attention_mask = attention_mask.view(attention_mask.size(0), -1)  \n",
    "            if ggnn_output is not None:\n",
    "\n",
    "                padding = torch.ones(input_ids.size(0), padding_length, dtype=input_ids.dtype, device=input_ids.device)  # (batch_size, num_nodes)\n",
    "                for i, num in enumerate(num_nodes):\n",
    "\n",
    "                    padding[i, :num] = 1\n",
    "\n",
    "                attention_mask = torch.cat((attention_mask, padding), dim=1)\n",
    "        \n",
    "\n",
    "        return super().generate(\n",
    "            input_ids=input_ids.view(input_ids.size(0), -1),\n",
    "            attention_mask=attention_mask.view(attention_mask.size(0), -1),\n",
    "            max_length=max_length,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    def wrap_encoder(self, use_checkpoint=False):\n",
    "        \"\"\"\n",
    "        Wrap T5 encoder to obtain a Fusion-in-Decoder model.\n",
    "        \"\"\"\n",
    "        self.encoder = EncoderWrapper(self.encoder, use_checkpoint=use_checkpoint)\n",
    "\n",
    "    def unwrap_encoder(self):\n",
    "        \"\"\"\n",
    "        Unwrap Fusion-in-Decoder encoder, useful to load T5 weights.\n",
    "        \"\"\"\n",
    "        self.encoder = self.encoder.encoder\n",
    "        block = []\n",
    "        for mod in self.encoder.block:\n",
    "            block.append(mod.module)\n",
    "        block = nn.ModuleList(block)\n",
    "        self.encoder.block = block\n",
    "\n",
    "    def load_t5(self, state_dict):\n",
    "        self.unwrap_encoder()\n",
    "        self.load_state_dict(state_dict,strict=False)\n",
    "        self.wrap_encoder()\n",
    "\n",
    "    def set_checkpoint(self, use_checkpoint):\n",
    "        \"\"\"\n",
    "        Enable or disable checkpointing in the encoder.\n",
    "        See https://pytorch.org/docs/stable/checkpoint.html\n",
    "        \"\"\"\n",
    "        for mod in self.encoder.encoder.block:\n",
    "            mod.use_checkpoint = use_checkpoint\n",
    "\n",
    "    def reset_score_storage(self):\n",
    "        \"\"\"\n",
    "        Reset score storage, only used when cross-attention scores are saved\n",
    "        to train a retriever.\n",
    "        \"\"\"\n",
    "        for mod in self.decoder.block:\n",
    "            mod.layer[1].EncDecAttention.score_storage = None\n",
    "\n",
    "    def get_crossattention_scores(self, context_mask):\n",
    "        \"\"\"\n",
    "        Cross-attention scores are aggregated to obtain a single scalar per\n",
    "        passage. This scalar can be seen as a similarity score between the\n",
    "        question and the input passage. It is obtained by averaging the\n",
    "        cross-attention scores obtained on the first decoded token over heads,\n",
    "        layers, and tokens of the input passage.\n",
    "\n",
    "        More details in Distilling Knowledge from Reader to Retriever:\n",
    "        https://arxiv.org/abs/2012.04584.\n",
    "        \"\"\"\n",
    "        scores = []\n",
    "        n_passages = context_mask.size(1)\n",
    "        for mod in self.decoder.block:\n",
    "            scores.append(mod.layer[1].EncDecAttention.score_storage)\n",
    "        scores = torch.cat(scores, dim=2)\n",
    "        bsz, n_heads, n_layers, _ = scores.size()\n",
    "        # batch_size, n_head, n_layers, n_passages, text_maxlength\n",
    "        scores = scores.view(bsz, n_heads, n_layers, n_passages, -1)\n",
    "        scores = scores.masked_fill(~context_mask[:, None, None], 0.)\n",
    "        scores = scores.sum(dim=[1, 2, 4])\n",
    "        ntokens = context_mask.sum(dim=[2]) * n_layers * n_heads\n",
    "        scores = scores/ntokens\n",
    "        return scores\n",
    "\n",
    "    def overwrite_forward_crossattention(self):\n",
    "        \"\"\"\n",
    "        Replace cross-attention forward function, only used to save\n",
    "        cross-attention scores.\n",
    "        \"\"\"\n",
    "        for mod in self.decoder.block:\n",
    "            attn = mod.layer[1].EncDecAttention\n",
    "            attn.forward = types.MethodType(cross_attention_forward, attn)\n",
    "\n",
    "class EncoderWrapper(torch.nn.Module):\n",
    "    def __init__(self, encoder, use_checkpoint=False):\n",
    "        super().__init__()\n",
    "        self.main_input_name = \"input_ids\"\n",
    "        # self.linear = nn.Linear(896, 768)  # 用于调整拼接后的 hidden state 大小\n",
    "        self.encoder = encoder\n",
    "        self.gnn_out = None\n",
    "        apply_checkpoint_wrapper(self.encoder, use_checkpoint)\n",
    "\n",
    "        # Query 和 Key 的线性变换，用于计算注意力权重\n",
    "        # self.query_layer = nn.Linear(768, 512)  # 用于对T5的hidden state进行投影\n",
    "        # self.key_layer = nn.Linear(768, 512)    # 用于对GNN的输出进行投影\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, ggnn_output=None, **kwargs):\n",
    "        # print(input_ids.size(),attention_mask.size())\n",
    "        outputs = self.encoder(input_ids[:,:512], attention_mask[:,:512], **kwargs)\n",
    "        # print('input_ids', input_ids.size())\n",
    "        if self.gnn_out is not None:\n",
    "            self.gnn_out = self.gnn_out.to('cuda:1')\n",
    "            encoder_hidden_states = outputs.last_hidden_state  # (batch_size, seq_len, hidden_dim)\n",
    "            # print(encoder_hidden_states.size())\n",
    "            # ggnn_output 是 (batch_size, 768)，我们需要将其转换为 query，变为 (batch_size, 1, 768)\n",
    "\n",
    "            encoder_hidden_states = torch.cat((encoder_hidden_states, self.gnn_out), dim=1)  # 替换填充部分\n",
    "            # print(encoder_hidden_states.size())\n",
    "\n",
    "\n",
    "            # print('outputs.last_hidden_state',outputs.last_hidden_state)\n",
    "            outputs.last_hidden_state = encoder_hidden_states\n",
    "\n",
    "        # print(outputs)\n",
    "        return outputs\n",
    "class CheckpointWrapper(torch.nn.Module):\n",
    "    def __init__(self, module, use_checkpoint=False):\n",
    "        super().__init__()\n",
    "        self.module = module\n",
    "        self.use_checkpoint = use_checkpoint\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask, position_bias, **kwargs):\n",
    "        if self.use_checkpoint and self.training:\n",
    "            kwargs = {k: v for k, v in kwargs.items() if v is not None}\n",
    "            def custom_forward(*inputs):\n",
    "                output = self.module(*inputs, **kwargs)\n",
    "                empty = torch.tensor(\n",
    "                    [],\n",
    "                    dtype=torch.float,\n",
    "                    device=output[0].device,\n",
    "                    requires_grad=True)\n",
    "                output = tuple(x if x is not None else empty for x in output)\n",
    "                return output\n",
    "\n",
    "            output = torch.utils.checkpoint.checkpoint(\n",
    "                custom_forward,\n",
    "                hidden_states,\n",
    "                attention_mask,\n",
    "                position_bias\n",
    "            )\n",
    "            output = tuple(x if x.size() != 0 else None for x in output)\n",
    "        else:\n",
    "            output = self.module(hidden_states, attention_mask, position_bias, **kwargs)\n",
    "        return output\n",
    "\n",
    "def apply_checkpoint_wrapper(t5stack, use_checkpoint):\n",
    "    block = []\n",
    "    for mod in t5stack.block:\n",
    "        wrapped_mod = CheckpointWrapper(mod, use_checkpoint)\n",
    "        block.append(wrapped_mod)\n",
    "    block = nn.ModuleList(block)\n",
    "    t5stack.block = block\n",
    "\n",
    "def cross_attention_forward(\n",
    "        self,\n",
    "        input,\n",
    "        mask=None,\n",
    "        kv=None,\n",
    "        position_bias=None,\n",
    "        past_key_value_state=None,\n",
    "        head_mask=None,\n",
    "        query_length=None,\n",
    "        use_cache=False,\n",
    "        output_attentions=False,\n",
    "    ):\n",
    "    assert(kv != None)\n",
    "    assert(head_mask == None)\n",
    "    assert(position_bias != None or self.has_relative_attention_bias)\n",
    "\n",
    "    bsz, qlen, dim = input.size()\n",
    "    n_heads, d_heads = self.n_heads, self.d_kv\n",
    "    klen = kv.size(1)\n",
    "\n",
    "    q = self.q(input).view(bsz, -1, n_heads, d_heads).transpose(1, 2)\n",
    "    if past_key_value_state == None:\n",
    "        k = self.k(kv).view(bsz, -1, n_heads, d_heads).transpose(1, 2)\n",
    "        v = self.v(kv).view(bsz, -1, n_heads, d_heads).transpose(1, 2)\n",
    "    else:\n",
    "        k, v = past_key_value_state\n",
    "\n",
    "    scores = torch.einsum(\"bnqd,bnkd->bnqk\", q, k)\n",
    "\n",
    "    if mask is not None:\n",
    "       scores += mask\n",
    "\n",
    "    if position_bias is None:\n",
    "        position_bias = self.compute_bias(qlen, klen)\n",
    "    scores += position_bias\n",
    "\n",
    "    if self.score_storage is None:\n",
    "        self.score_storage = scores\n",
    "\n",
    "    attn = F.softmax(scores.float(), dim=-1).type_as(scores)\n",
    "    attn = F.dropout(attn, p=self.dropout, training=self.training)\n",
    "\n",
    "    output = torch.matmul(attn, v)\n",
    "    output = output.transpose(1, 2).contiguous().view(bsz, -1, self.inner_dim)\n",
    "    output = self.o(output)\n",
    "\n",
    "    if use_cache:\n",
    "        output = (output,) + ((k, v),)\n",
    "    else:\n",
    "        output = (output,) + (None,)\n",
    "\n",
    "    if output_attentions:\n",
    "        output = output + (attn,)\n",
    "\n",
    "    if self.has_relative_attention_bias:\n",
    "        output = output + (position_bias,)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "import transformers\n",
    "import dgl\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    '/home/hdd/qingao/cache/huggingface/transformers/models--Salesforce--codet5-base/snapshots/4078456db09ba972a3532827a0b5df4da172323c'\n",
    "    )\n",
    "tokenizer.add_tokens([\"Vul_Start\",\"Vul_End\"])\n",
    "model = transformers.T5ForConditionalGeneration.from_pretrained(\n",
    "    '/home/hdd/qingao/cache/huggingface/transformers/models--Salesforce--codet5-base/snapshots/4078456db09ba972a3532827a0b5df4da172323c'\n",
    "    )\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.load_state_dict(torch.load('/home/hdd/qingao/DeepDFA/CodeT5/saved_models/repair/codeT5/checkpoint-best-acc/pytorch_model.bin'))\n",
    "config = model.config\n",
    "\n",
    "\n",
    "input_dim = 8\n",
    "feat = \"_ABS_DATAFLOW_datatype_all_limitall_1000_limitsubkeys_1000\"\n",
    "gtype = \"cfg\"\n",
    "label_style = \"graph\"\n",
    "dsname = \"bigvul\"\n",
    "node_type_feat = None\n",
    "concat_all_absdf = True\n",
    "hidden_dim = 192\n",
    "n_steps = 3\n",
    "num_output_layers = 3\n",
    "\n",
    "flowgnn_model = FlowGNNGGNNModule(\n",
    "    feat,\n",
    "    input_dim,\n",
    "    hidden_dim,\n",
    "    n_steps,\n",
    "    num_output_layers,\n",
    "    label_style=label_style,\n",
    "    # freeze_graph=False,\n",
    "    # append_dataflow=\"before_graph\",\n",
    "    # codebert_feat=None,\n",
    "    # doc2vec_feat=None,\n",
    "    # glove_feat=None,\n",
    "    # num_node_types=flowgnn_datamodule.num_node_types,\n",
    "    # node_type_feat=node_type_feat,\n",
    "    # just_codebert=False,\n",
    "    concat_all_absdf=concat_all_absdf,\n",
    "    # undersample_node_on_loss_factor=None,\n",
    "    # test_every=False,\n",
    "    # tune_nni=False,\n",
    "    # positive_weight=None,\n",
    "    encoder_mode=True,\n",
    ")\n",
    "\n",
    "\n",
    "flow_model = FLOWT5(config,flow_gnn=flowgnn_model)\n",
    "flow_model.load_t5(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/410 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] Train loss 0.024: 100%|██████████| 410/410 [07:54<00:00,  1.16s/it]\n",
      "eval: 100%|██████████| 903/903 [14:28<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n",
      "Save the best acc model into %s home/hdd/qingao/RMGArepair/saved_model/ab_nodes/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1] Train loss 0.022: 100%|██████████| 410/410 [07:43<00:00,  1.13s/it]\n",
      "eval: 100%|██████████| 903/903 [14:36<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184\n",
      "Save the best acc model into %s home/hdd/qingao/RMGArepair/saved_model/ab_nodes/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2] Train loss 0.02: 100%|██████████| 410/410 [07:43<00:00,  1.13s/it] \n",
      "eval: 100%|██████████| 903/903 [13:28<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[3] Train loss 0.019: 100%|██████████| 410/410 [07:44<00:00,  1.13s/it]\n",
      "eval: 100%|██████████| 903/903 [13:48<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[4] Train loss 0.019: 100%|██████████| 410/410 [07:48<00:00,  1.14s/it]\n",
      "eval: 100%|██████████| 903/903 [13:37<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] Train loss 0.022: 100%|██████████| 410/410 [07:45<00:00,  1.14s/it]\n",
      "eval: 100%|██████████| 903/903 [15:30<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1] Train loss 0.026: 100%|██████████| 410/410 [07:46<00:00,  1.14s/it]\n",
      "eval: 100%|██████████| 903/903 [14:04<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2] Train loss 0.022: 100%|██████████| 410/410 [07:44<00:00,  1.13s/it]\n",
      "eval: 100%|██████████| 903/903 [15:02<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[3] Train loss 0.017: 100%|██████████| 410/410 [07:46<00:00,  1.14s/it]\n",
      "eval: 100%|██████████| 903/903 [14:50<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[4] Train loss 0.013: 100%|██████████| 410/410 [07:44<00:00,  1.13s/it]\n",
      "eval: 100%|██████████| 903/903 [13:37<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189\n",
      "Save the best acc model into %s home/hdd/qingao/RMGArepair/saved_model/ab_nodes/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[5] Train loss 0.012: 100%|██████████| 410/410 [07:43<00:00,  1.13s/it]\n",
      "eval: 100%|██████████| 903/903 [13:27<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[6] Train loss 0.012: 100%|██████████| 410/410 [07:43<00:00,  1.13s/it]\n",
      "eval: 100%|██████████| 903/903 [13:22<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[7] Train loss 0.012: 100%|██████████| 410/410 [07:42<00:00,  1.13s/it]\n",
      "eval: 100%|██████████| 903/903 [13:21<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[8] Train loss 0.012: 100%|██████████| 410/410 [07:42<00:00,  1.13s/it]\n",
      "eval: 100%|██████████| 903/903 [13:13<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[9] Train loss 0.012: 100%|██████████| 410/410 [07:42<00:00,  1.13s/it]\n",
      "eval: 100%|██████████| 903/903 [13:16<00:00,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import os \n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 1e-5\n",
    "num_epochs = 5\n",
    "best_em = 0\n",
    "\n",
    "output_dir = 'home/hdd/qingao/RMGArepair/saved_model/ab_nodes/'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "for param in flow_model.flow_gnn.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in flow_model.encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in flow_model.decoder.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "\n",
    "\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in flow_model.named_parameters() if not any(nd in n for nd in no_decay) and p.requires_grad],\n",
    "     'weight_decay': 1e-4\n",
    "     },\n",
    "    {'params': [p for n, p in flow_model.named_parameters() if any(nd in n for nd in no_decay) and p.requires_grad], \n",
    "     'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=lr, eps=1e-8)\n",
    "# for name, param in flow_model.flow_gnn.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(f\"Parameter: {name}, Value: {param.data}, Gradient: {param.grad}\")\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=400,\n",
    "    num_training_steps=(len(train_dataloader) * num_epochs),\n",
    ")\n",
    "# scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "#                                             num_warmup_steps=args.warmup_steps,\n",
    "#                                             num_training_steps=num_train_optimization_steps)\n",
    "\n",
    "\n",
    "gradient_accumulation_steps = 1\n",
    "\n",
    "for cur_epoch in range(0, num_epochs):\n",
    "    bar = tqdm(train_dataloader, total=len(train_dataloader), desc=\"Training\")\n",
    "    nb_tr_examples, nb_tr_steps, tr_loss = 0, 0, 0\n",
    "    flow_model.to('cuda:1')\n",
    "    flow_model.train()\n",
    "    \n",
    "    for step, batch in enumerate(bar):\n",
    "        input_ids = batch['input_ids'].to('cuda:1')\n",
    "        attention_mask = batch['attention_mask'].to('cuda:1')\n",
    "        labels = batch['labels'].to('cuda:1')\n",
    "        index = batch['index'].to('cuda:1')\n",
    "\n",
    "        index_list = index.tolist()\n",
    "\n",
    "        if graphs_by_id is None:\n",
    "            graphs = None\n",
    "        else:\n",
    "            graphs = [graphs_by_id[i].to('cuda:1') for i in index_list if i in graphs_by_id]\n",
    "\n",
    "            outputs = flow_model(input_ids=input_ids, attention_mask=attention_mask,\n",
    "                                 labels=labels,\n",
    "                                 graph=graphs if graphs else None)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        nb_tr_examples += input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        loss.backward()\n",
    "\n",
    "        if nb_tr_steps % gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            # print(\"Flow GNN Parameters and Gradients:\")\n",
    "            # for name, param in flow_model.flow_gnn.named_parameters():\n",
    "            #     if param.requires_grad:\n",
    "            #         print(f\"Parameter: {name}, Value: {param.data}, Gradient: {param.grad}\")\n",
    "            # break\n",
    "\n",
    "            train_loss = round(tr_loss / nb_tr_steps, 4) if nb_tr_steps > 0 else 0\n",
    "            bar.set_description(\"[{}] Train loss {}\".format(cur_epoch, round(train_loss, 3)))\n",
    "    em = eval(flow_model,eval_dataloader,graphs_by_id)\n",
    "    print(em)\n",
    "    if em>best_em:\n",
    "        best_em = em\n",
    "        output_model_file = os.path.join(output_dir, \"pytorch_model.bin\")\n",
    "        torch.save(flow_model.state_dict(), output_model_file)\n",
    "        print(\"Save the best acc model into %s\", output_model_file)\n",
    "for param in flow_model.flow_gnn.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in flow_model.encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in flow_model.decoder.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "\n",
    "\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in flow_model.named_parameters() if not any(nd in n for nd in no_decay) and p.requires_grad],\n",
    "     'weight_decay': 1e-2},\n",
    "    {'params': [p for n, p in flow_model.named_parameters() if any(nd in n for nd in no_decay) and p.requires_grad], \n",
    "     'weight_decay': 0.0}\n",
    "]\n",
    "lr = 1e-4\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=lr, eps=1e-8)\n",
    "# for name, param in flow_model.flow_gnn.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(f\"Parameter: {name}, Value: {param.data}, Gradient: {param.grad}\")\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=400,\n",
    "    num_training_steps=(len(train_dataloader) * num_epochs),\n",
    ")\n",
    "# scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "#                                             num_warmup_steps=args.warmup_steps,\n",
    "#                                             num_training_steps=num_train_optimization_steps)\n",
    "\n",
    "\n",
    "gradient_accumulation_steps = 1\n",
    "# 训练循环\n",
    "for cur_epoch in range(0, 10):\n",
    "    bar = tqdm(train_dataloader, total=len(train_dataloader), desc=\"Training\")\n",
    "    nb_tr_examples, nb_tr_steps, tr_loss = 0, 0, 0\n",
    "    flow_model.to('cuda:1')\n",
    "    flow_model.train()\n",
    "    \n",
    "    for step, batch in enumerate(bar):\n",
    "        input_ids = batch['input_ids'].to('cuda:1')\n",
    "        attention_mask = batch['attention_mask'].to('cuda:1')\n",
    "        labels = batch['labels'].to('cuda:1')\n",
    "        index = batch['index'].to('cuda:1')\n",
    "\n",
    "        index_list = index.tolist()\n",
    "\n",
    "        if graphs_by_id is None:\n",
    "            graphs = None\n",
    "        else:\n",
    "            graphs = [graphs_by_id[i].to('cuda:1') for i in index_list if i in graphs_by_id]\n",
    "\n",
    "            outputs = flow_model(input_ids=input_ids, attention_mask=attention_mask,\n",
    "                                 labels=labels,\n",
    "                                 graph=graphs if graphs else None)\n",
    "            \n",
    "\n",
    "\n",
    "        loss = outputs.loss\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        nb_tr_examples += input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        loss.backward()\n",
    "\n",
    "        if nb_tr_steps % gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            # print(\"Flow GNN Parameters and Gradients:\")\n",
    "            # for name, param in flow_model.flow_gnn.named_parameters():\n",
    "            #     if param.requires_grad:\n",
    "            #         print(f\"Parameter: {name}, Value: {param.data}, Gradient: {param.grad}\")\n",
    "            # break\n",
    "\n",
    "            train_loss = round(tr_loss / nb_tr_steps, 4) if nb_tr_steps > 0 else 0\n",
    "            bar.set_description(\"[{}] Train loss {}\".format(cur_epoch, round(train_loss, 3)))\n",
    "    em = eval(flow_model,eval_dataloader,graphs_by_id)\n",
    "    print(em)\n",
    "    if em>best_em:\n",
    "        best_em = em\n",
    "        output_model_file = os.path.join(output_dir, \"pytorch_model.bin\")\n",
    "        torch.save(flow_model.state_dict(), output_model_file)\n",
    "        print(\"Save the best acc model into %s\", output_model_file)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepdfa2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
